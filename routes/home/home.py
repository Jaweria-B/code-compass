# routes/home.py

import streamlit as st
from openai import AzureOpenAI
import os

# Function to handle user input and provide response
def handle_user_input(input_message):
    # Check if the user has entered a topic
    if input_message:
        # Process the input (for example, you can save it to a variable)
        topic = input_message.strip()
        
        # Provide a response acknowledging the topic entered by the user
        st.chat_message("ai").write(f"You want to learn about {topic}. Let me generate a learning path for you!")


def home_page():    
    st.write("""
        ###### Explore personalized learning paths, quizzes, real-world projects, and more!\n 
        ## "What technology do you want to learn today?"
    """)

    # Adding a header
    st.header()

    topic = None

    # Get user input using chat_input
    if user_input := st.chat_input("Please enter the topic you want to learn about:"):
        topic = handle_user_input(user_input)

    if topic:
        # Constructing the prompt string
        prompt = f"""
        You are an AI assistant that helps people find information.
        The user wants to learn about {topic}.
        You will provide a comprehensive learning path covering all essential topics to master {topic}.
        This includes core concepts, programming languages, frameworks and libraries, development environment setup, key skills and techniques, advanced concepts, best practices and standards, and real-world projects.

        Once the initial learning path is provided, you will ask the user if they want additional or extra information on {topic}.
        If they confirm, you will provide further details on advanced topics, recent developments, or other relevant information.

        Please wait while you generate the learning path for {topic}.
        """

        # Initialize the AzureOpenAI client
        client = AzureOpenAI(
            azure_endpoint="https://march-may-project.openai.azure.com/",
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version="2024-02-15-preview"
        )

        message_text = [{"role":"system","content":prompt}]


        # Create a completion request to generate text using the GPT-4 Turbo model
        completion = client.chat.completions.create(
            model="code-compass-gpt-4", # model = "deployment_name"
            messages = message_text,
            temperature=0.7,
            max_tokens=800,
            top_p=0.95,
            frequency_penalty=0,
            presence_penalty=0,
            stop=None
        )

        # Display the response generated by the AI model
        st.subheader("Learning Path:")
        st.write(completion.choices[0].message.content)

    
        