# routes/home.py

from dotenv import load_dotenv
import streamlit as st
from openai import AzureOpenAI
import os

load_dotenv()

# Initialize the AzureOpenAI client
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version="2024-02-15-preview"
)

def is_topic(input):
    prompt = f"""
    This is the input: {input} given by user. See if the input: {input} has name of any technology that user wants to learn about then return the name of that technology, else return False  
    """            

    message_text = [{"role":"system","content":prompt}]


    # Create a completion request to generate text using the GPT-4 Turbo model
    completion = client.chat.completions.create(
        model="code-compass-gpt-4", # model = "deployment_name"
        messages = message_text,
        temperature=0.7,
        max_tokens=800,
        top_p=0.95,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )


    topic = completion.choices[0].message.content
    return topic

# Function to handle user input and provide response
def handle_user_input(input_message):
    # Check if the user has entered a topic
    if input_message:
        # Process the input (for example, you can save it to a variable)
        input = input_message.strip()

        topic = is_topic(input)
        
        # Provide a response acknowledging the topic entered by the user
        st.chat_message("ai").write(f"You want to learn about {topic}. Let me generate a learning path for you!")

        return (topic, input_message)
    
def generate_paths(topic, difficulty_level):
      
    # Constructing the prompt string
    prompt = f"""
    You are an AI assistant that helps people find information.
    The user wants to learn about {topic}. The difficulty Level is {difficulty_level}
    You will provide a comprehensive learning path covering all essential topics to master {topic} according to this difficulty level: {difficulty_level}.
    This includes core concepts, programming languages, frameworks and libraries, development environment setup, key skills and techniques, advanced concepts.
    """            

    message_text = [{"role":"system","content":prompt}]


    # Create a completion request to generate text using the GPT-4 Turbo model
    completion = client.chat.completions.create(
        model="code-compass-gpt-4", # model = "deployment_name"
        messages = message_text,
        temperature=0.7,
        max_tokens=800,
        top_p=0.95,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )

    # Display the response generated by the AI model
    st.subheader("Learning Path:")
    learning_path = completion.choices[0].message.content
    return learning_path

# best practices and standards, and real-world projects

def home_page():   

    st.write("""
            ###### Explore personalized learning paths, quizzes, real-world projects, and more!
        """)

    col1, col2 = st.columns(2)
    with col1:
        st.write("""
            ### "What technology do you want to learn today?"
        """)
    
    with col2:
        # Select the level of difficulty for the learning path
        difficulty_level = st.radio("Select the level of learning path:", ("Easy", "Medium", "Hard"))

    # Get user input using chat_input
    if user_input := st.chat_input("Please enter the topic you want to learn about:"):
        input = handle_user_input(user_input)
        topic, input_message = input[0], input[1]
    
    if topic != False:
        learning_path = generate_paths(topic, difficulty_level)

    # Constructing the prompt string
    prompt = f"""
    You are an AI assistant that helps people find information.

    See the {input_message}, if {topic} is not False, that means user wants to know abput the learning path of some technology, that learning path is in {learning_path}, return that learning path to user. 
    
    If {topic} is False, means user has not entered any technology name, and you simply answer him accoring the input statement {input_message}
    """
    message_text = [{"role":"system","content":prompt}]


    # Create a completion request to generate text using the GPT-4 Turbo model
    completion = client.chat.completions.create(
        model="code-compass-gpt-4", # model = "deployment_name"
        messages = message_text,
        temperature=0.7,
        max_tokens=800,
        top_p=0.95,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )
    

    completion.choices[0].message.content
